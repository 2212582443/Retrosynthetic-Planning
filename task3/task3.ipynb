{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\n\nfrom torch.utils.data import DataLoader, Dataset,TensorDataset,ConcatDataset\nfrom sklearn import preprocessing\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\n\npath = 'Project for ML/schneider50k/'\n'''\n# 加载数据集文件\ntrain_dataset = torch.load(path+\"train_dataset.pt\")\ntest_dataset = torch.load(path+\"test_dataset.pt\")\nval_dataset = torch.load(path+\"val_dataset.pt\")\n'''\ntrain_dataset = torch.load(path+\"train_filter_dataset.pt\")\ntest_dataset = torch.load(path+\"test_filter_dataset.pt\")\nval_dataset = torch.load(path+\"val_filter_dataset.pt\")\n\n# 提取所有的y并组成一个array类型的列表\ntrain_features = []\ntrain_labels = []\ntest_features = []\ntest_labels = []\nval_features = []\nval_labels = []\nfor train_sample in train_dataset:\n    train_feature,train_label = train_sample\n    train_features.append(train_feature)\n    train_labels.append(train_label)\n\nfor test_sample in test_dataset:\n    test_feature,test_label = test_sample\n    test_features.append(test_feature)\n    test_labels.append(test_label)\n\nfor val_sample in val_dataset:\n    val_feature,val_label = val_sample\n    val_features.append(val_feature)\n    val_labels.append(val_label)\n\nlabel_num = preprocessing.LabelEncoder()\nlabel_num.fit(train_labels+test_labels+val_labels)\n\ntrain_labels_num = label_num.transform(train_labels)\ntest_labels_num = label_num.transform(test_labels)\nval_labels_num = label_num.transform(val_labels)\n\n\n\n# 定义神经网络模型\nclass Classifer(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(Classifer, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        self.fc4 = nn.Linear(256, output_dim)\n        self.dropout = nn.Dropout(p=0.3)\n        self.relu = nn.ReLU()\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc4(x)\n        x = self.softmax(x)\n        return x\n\nclass ZSLCrossEntropyLoss(nn.Module):\n        def __init__(self, weight_decay=0.001):\n            super(ZSLCrossEntropyLoss, self).__init__()\n            self.loss_fn = nn.CrossEntropyLoss()\n            self.weight_decay = weight_decay\n\n        def forward(self, logits, targets, params=None):\n            loss = self.loss_fn(logits, targets)\n\n            # 计算L2范数\n            l2_reg = 0\n            if params is not None:\n                for param in params:\n                    l2_reg += torch.norm(param, p=2)**2\n            else:\n                for param in self.parameters():\n                    l2_reg += torch.norm(param, p=2)**2\n\n            # 加入L2正则化项\n            loss += self.weight_decay * l2_reg\n\n            return loss\n        \n# 定义数据集及其相关的参数\ntrain_dataset = TensorDataset(torch.tensor(np.array(train_features,dtype=np.float32)),torch.tensor(np.array(train_labels_num)))\ntest_dataset = TensorDataset(torch.tensor(np.array(test_features,dtype=np.float32)),torch.tensor(np.array(test_labels_num)))\nval_dataset = TensorDataset(torch.tensor(np.array(val_features,dtype=np.float32)),torch.tensor(np.array(val_labels_num)))\ninput_size = train_dataset[0][0].shape[0]\nhidden_size = 256\nnum_classes = len(label_num.classes_)\nbatch_size = 64\nnum_epochs = 1000\nlr = 0.05\n\ntrain_dataset = ConcatDataset([train_dataset, val_dataset])\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n#val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Classifer(input_size, num_classes).to(device)\nloss_fn = ZSLCrossEntropyLoss()\nloss_fn = loss_fn.to(device)\noptimizer = optim.SGD(model.parameters(), lr=lr)\n\n\n\n\n# 训练模型\nloss_list = []\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for i, (features, labels) in enumerate(train_loader):\n        # 将数据移动到GPU\n        features = features.to(device)\n        labels = labels.to(device)\n        \n        # 前向传播\n        outputs = model(features)\n        loss = loss_fn(outputs, labels.long(),params=model.parameters())\n        \n        # 反向传播和优化\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * features.size(0)\n        \n        if (i+1) % 100 == 0:\n            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n    \n    epoch_loss = running_loss / len(train_dataset)\n    loss_list.append(epoch_loss)\n\nplt.plot(loss_list)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss Curve')\nplt.show()\n\ntorch.save(model.state_dict(),path+'model_filter.pt')\n# 在测试集上评估模型\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for features, labels in test_loader:\n        # 将数据移动到GPU\n        features = features.to(device)\n        labels = labels.to(device)\n\n        # 前向传播\n        outputs = model(features)\n        _, predicted = torch.max(outputs.data, dim=1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the network on the test features: {} %'.format(100 * correct / total))\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\n\nfrom torch.utils.data import DataLoader, Dataset,TensorDataset,ConcatDataset\nfrom sklearn import preprocessing\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\n\npath = '/kaggle/input/important2/Project for ML/schneider50k/'\n# 加载template与数字对应文件\nlabels_num =pd.read_csv(path+'labels_nums_filter.csv',header=None)\nlabels_num = list(labels_num[0])\n\n# 加载数据集文件\ntest_dataset = torch.load(path+\"test_filter_dataset.pt\")\ntest_features = []\ntest_labels = []\nfor test_sample in test_dataset:\n    test_feature,test_label = test_sample\n    test_features.append(test_feature)\n    test_labels.append(test_label)\ntest_labels_num = [labels_num.index(label) for label in test_labels]\ntest_dataset = TensorDataset(torch.tensor(np.array(test_features,dtype=np.float32)),torch.tensor(np.array(test_labels_num)))\n\n# 定义神经网络模型\nclass Classifer(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(Classifer, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        self.fc4 = nn.Linear(256, output_dim)\n        self.dropout = nn.Dropout(p=0.3)\n        self.relu = nn.ReLU()\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc4(x)\n        x = self.softmax(x)\n        return x\n    \n# 定义数据集及其相关的参数\ninput_size = 2048\nnum_classes = len(labels_num)\nbatch_size = 64\n\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Classifer(input_size, num_classes).to(device)\nmodel.load_state_dict(torch.load(path+'model_filter.pt'))\n\n# 在测试集上评估模型\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for features, labels in test_loader:\n        # 将数据移动到GPU\n        features = features.to(device)\n        labels = labels.to(device)\n\n        # 前向传播\n        outputs = model(features)\n        _, predicted = torch.max(outputs.data, dim=1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the network on the test features: {} %'.format(100 * correct / total))\n\ndef split_reaction(reaction):\n    rct, prd = reaction.split('>>')\n    prd_mols = [x for x in prd.split('.')]\n    \n    reactions = []\n    for p in prd_mols:\n        reaction = [rct].copy()\n        reaction.append(p)\n        reactions.append(reaction)\n    \n    return reactions\n#随便找个进行预测\n\nfeature = test_dataset[144][0].unsqueeze(0).to(device)\n\noutput = model(feature)\n_, predicted = torch.max(output.data, dim=1)\nprint(labels_num[int(predicted)])\nprint(split_reaction(labels_num[int(predicted)]))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-16T13:10:41.198919Z","iopub.execute_input":"2023-06-16T13:10:41.199275Z","iopub.status.idle":"2023-06-16T13:10:41.307826Z","shell.execute_reply.started":"2023-06-16T13:10:41.199246Z","shell.execute_reply":"2023-06-16T13:10:41.306830Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test features: 49.331103678929765 %\n[C:2]-[NH;D2;+0:1]-[C:3]>>C-C(-C)(-C)-O-C(=O)-[N;H0;D3;+0:1](-[C:2])-[C:3]\n[['[C:2]-[NH;D2;+0:1]-[C:3]', 'C-C(-C)(-C)-O-C(=O)-[N;H0;D3;+0:1](-[C:2])-[C:3]']]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T13:08:19.875050Z","iopub.execute_input":"2023-06-16T13:08:19.875413Z","iopub.status.idle":"2023-06-16T13:08:19.884515Z","shell.execute_reply.started":"2023-06-16T13:08:19.875384Z","shell.execute_reply":"2023-06-16T13:08:19.883536Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"<torch.utils.data.dataset.TensorDataset object at 0x7e0e54793a90>\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\n\n# Define the model architecture for single-step retrosynthesis prediction\nclass RetrosynthesisModel(torch.nn.Module):\n\n    def __init__(self, num_atom_types, num_bond_types, hidden_size):\n        super(RetrosynthesisModel, self).__init__()\n\n        self.embedding = torch.nn.Embedding(num_atom_types + num_bond_types, hidden_size)\n        self.encoder = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.decoder = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.output = torch.nn.Linear(hidden_size, num_atom_types + num_bond_types)\n\n    def forward(self, inputs, targets=None):\n        embedded = self.embedding(inputs)\n        encoded_states, _ = self.encoder(embedded)\n        if targets is not None:\n            targets_embedded = self.embedding(targets)\n            decoded_states, _ = self.decoder(targets_embedded, encoded_states[:, -1:, :])\n            outputs = self.output(decoded_states.squeeze(1))\n        else:\n            outputs = self.output(encoded_states)\n        return outputs\n\n\n# Load the pre-trained model for Task 1\ndef load_model_task1():\n    model = RetrosynthesisModel(num_atom_types=len(AllChem.GetPeriodicTable().GetElements()),\n                                num_bond_types=len(Chem.rdchem.BondType.values),\n                                hidden_size=128)\n    model.load_state_dict(torch.load('/kaggle/input/important2/Project for ML/schneider50k/model_filter.pt', map_location=torch.device('cpu')))\n    model.eval()\n    return model\n\n\n# Define a function to generate possible reactants for a given molecule using the trained model from Task 1\ndef generate_possible_reactants(model, target_molecule):\n    with torch.no_grad():\n        product_fp = get_fingerprint([target_molecule])[0]\n        product_fp_tensor = torch.tensor(product_fp, dtype=torch.float32).unsqueeze(0)\n        predicted_reactant_fps = model(product_fp_tensor).sigmoid().round().squeeze().tolist()\n        possible_reactants = []\n        for fp in predicted_reactant_fps:\n            reactant_mol = Chem.MolFromSmiles(fingerprints_to_smiles(np.unpackbits(fp)))\n            if reactant_mol is not None:\n                possible_reactants.append(reactant_mol)\n        return possible_reactants\n\n\n# Define a function to predict the reaction template for a given pair of reactants and products\ndef predict_reaction_template(model, reactant_mol, product_mol):\n    with torch.no_grad():\n        reactant_fp = get_fingerprint([reactant_mol])[0]\n        product_fp = get_fingerprint([product_mol])[0]\n        reactant_fp_tensor = torch.tensor(reactant_fp, dtype=torch.float32).unsqueeze(0)\n        product_fp_tensor = torch.tensor(product_fp, dtype=torch.float32).unsqueeze(0)\n        predicted_template = model(reactant_fp_tensor, product_fp_tensor).argmax(-1).item()\n        return predicted_template\n\n\n# Define a helper function to convert Morgan fingerprints to SMILES strings\ndef fingerprints_to_smiles(fp):\n    bv = np.zeros((1,))\n    np.put(bv, np.arange(len(fp)), fp)\n    mol = Chem.MolFromSmiles('')\n    fp = AllChem.DataStructs.cDataStructs.ExplicitBitVect(2048, bv)\n    return Chem.MolToSmiles(AllChem.ReconstructRDKitMol(fp, mol))\n    \n\n# Define a function to convert reactant molecules to Morgan fingerprints\ndef get_fingerprint(reactants_mol):\n    fps = []\n    for mol in reactants_mol:\n        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n        arr = np.zeros((1,))\n        AllChem.DataStructs.ConvertToNumpyArray(fp, arr)\n        fps.append(np.packbits(arr))\n    return fps\n","metadata":{"execution":{"iopub.status.busy":"2023-06-16T13:04:45.347424Z","iopub.execute_input":"2023-06-16T13:04:45.347817Z","iopub.status.idle":"2023-06-16T13:04:45.367595Z","shell.execute_reply.started":"2023-06-16T13:04:45.347786Z","shell.execute_reply":"2023-06-16T13:04:45.366726Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from rdkit import Chem\nfrom rdkit.Chem import AllChem\n\n# Load the models for Tasks 1 and 2\nmodel_task1 = load_model_task1()\nmodel_task2 = load_model_task2()\n\n# Define the target molecule and product molecule for Task 3\ntarget_mol = 'CC(=O)Nc1ccc(C(=O)O)c(c1)C(=O)O'\nproduct_mol = 'CC(=O)Nc1ccc(cc1C(=O)O)C(=O)O'\n\n# Convert the target and product molecules to RDKit molecules\ntarget_mol = Chem.MolFromSmiles(target_mol)\nproduct_mol = Chem.MolFromSmiles(product_mol)\n\n# Generate possible reactants for the target molecule using the model from Task 1\npossible_reactants = generate_possible_reactants(model_task1, target_mol)\n\n# Evaluate the cost of each possible reactant using the model from Task 2\nreactant_costs = []\nfor reactant in possible_reactants:\n    fp = get_fingerprint([reactant])[0]\n    cost = evaluate_cost(model_task2, fp)\n    reactant_costs.append(cost)\n\n# Choose the reactant with the lowest cost as the starting material for synthesis planning (Task 3)\nstarting_reactant = possible_reactants[np.argmin(reactant_costs)]\n\n# Predict the reaction template for the synthesis pathway using the models from Tasks 1 and 3\nreaction_template = predict_reaction_template(model_task1, starting_reactant, product_mol)\n\n# Print the results\nprint('Possible reactants: ', [Chem.MolToSmiles(mol) for mol in possible_reactants])\nprint('Reactant costs: ', reactant_costs)\nprint('Starting material: ', Chem.MolToSmiles(starting_reactant))\nprint('Reaction template: ', reaction_template)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\n\n# Define the model architecture for multi-step retrosynthesis planning\nclass MultiStepRetrosynthesisModel(torch.nn.Module):\n\n    def __init__(self, num_atom_types, num_bond_types, hidden_size):\n        super(MultiStepRetrosynthesisModel, self).__init__()\n\n        self.embedding = torch.nn.Embedding(num_atom_types + num_bond_types, hidden_size)\n        self.encoder = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.decoder = torch.nn.GRU(hidden_size + 1, hidden_size, batch_first=True)\n        self.output = torch.nn.Linear(hidden_size, num_atom_types + num_bond_types)\n\n    def forward(self, inputs, targets=None):\n        embedded = self.embedding(inputs[:, :-1])\n        encoded_states, _ = self.encoder(embedded)\n        if targets is not None:\n            targets_embedded = self.embedding(targets[:, :-1])\n            decoder_input = torch.cat([targets[:, -1:, :], targets_embedded], dim=-1)\n            decoded_states, _ = self.decoder(decoder_input, encoded_states[:, -1:, :])\n            outputs = self.output(decoded_states.squeeze(1))\n        else:\n            outputs = self.output(encoded_states)\n        return outputs\n\n\n# Load the pre-trained model for Task 2\ndef load_model_task2():\n    model = MultiStepRetrosynthesisModel(num_atom_types=117,\n                                         num_bond_types=6,\n                                         hidden_size=128)\n    model.load_state_dict(torch.load('model_task2.pt', map_location=torch.device('cpu')))\n    model.eval()\n    return model\n\n\n# Define a function to evaluate the cost of a given reactant using the trained model from Task 2\ndef evaluate_cost(model, reactant_fp):\n    with torch.no_grad():\n        reactant_fp_tensor = torch.tensor(reactant_fp, dtype=torch.float32).unsqueeze(0)\n        predicted_cost = model(reactant_fp_tensor).squeeze().item()\n        return predicted_cost\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\n\nfrom torch.utils.data import DataLoader, Dataset,TensorDataset,ConcatDataset\nfrom sklearn import preprocessing\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\n\npath = '/kaggle/input/important2/Project for ML/schneider50k/'\n# 加载template与数字对应文件\nlabels_num =pd.read_csv(path+'labels_nums_filter.csv',header=None)\nlabels_num = list(labels_num[0])\n\n# 加载数据集文件\ntest_dataset = torch.load(path+\"test_filter_dataset.pt\")\ntest_features = []\ntest_labels = []\nfor test_sample in test_dataset:\n    test_feature,test_label = test_sample\n    test_features.append(test_feature)\n    test_labels.append(test_label)\ntest_labels_num = [labels_num.index(label) for label in test_labels]\ntest_dataset = TensorDataset(torch.tensor(np.array(test_features,dtype=np.float32)),torch.tensor(np.array(test_labels_num)))\n\n# 定义神经网络模型\nclass Classifer(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(Classifer, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        self.fc4 = nn.Linear(256, output_dim)\n        self.dropout = nn.Dropout(p=0.3)\n        self.relu = nn.ReLU()\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc4(x)\n        x = self.softmax(x)\n        return x\n    \n# 定义数据集及其相关的参数\ninput_size = 2048\nnum_classes = len(labels_num)\nbatch_size = 64\n\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Classifer(input_size, num_classes).to(device)\nmodel.load_state_dict(torch.load(path+'model_filter.pt'))\n\n# 在测试集上评估模型\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for features, labels in test_loader:\n        # 将数据移动到GPU\n        features = features.to(device)\n        labels = labels.to(device)\n\n        # 前向传播\n        outputs = model(features)\n        _, predicted = torch.max(outputs.data, dim=1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the network on the test features: {} %'.format(100 * correct / total))\n\ndef split_reaction(reaction):\n    rct, prd = reaction.split('>>')\n    prd_mols = [x for x in prd.split('.')]\n    \n    reactions = []\n    for p in prd_mols:\n        reaction = [rct].copy()\n        reaction.append(p)\n        reactions.append(reaction)\n    \n    return reactions\n#随便找个进行预测\ndef get_mfp(product):\n    mol = Chem.MolFromSmarts(product)\n    fp = AllChem.GetMorganFingerprintAsBitVect(mol,2,nBits=2048)\n    onbits = list(fp.GetOnBits())\n    arr = np.zeros(fp.GetNumBits(),dtype = bool)\n    arr[onbits] = 1\n    return arr\ntempa = get_mfp(\"[C:4]-[N;H0;D3;+0:5](-[C:6])-[C;H0;D3;+0:1](-[C:2])=[O;D1;H0:3]\")\nfeature = tempa.unsqueeze(0).to(device)\n\noutput = model(feature)\n_, predicted = torch.max(output.data, dim=1)\nprint(labels_num[int(predicted)])\nprint(split_reaction(labels_num[int(predicted)]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom rdkit import Chem\n\n# 导入\n#model1 = load_model_task1()\n#model2 = load_model_task2()\n\n# Depth-first search\ndef dfs(curr_mol, target_mol):\n    # 搜索结束\n    if curr_mol == target_mol:\n        return [Chem.MolToSmiles(curr_mol)]\n\n    # task1\n    output = model(feature)\n    _, predicted = torch.max(output.data, dim=1)\n    print(labels_num[int(predicted)])\n    print(split_reaction(labels_num[int(predicted)]))\n    \n    possible_reactants = generate_possible_reactants(model1, curr_mol)\n\n    next_mol = possible_reactants[0]\n\n    # 递归\n    child_paths = []\n    if next_mol is not None:\n        child_paths = [dfs(next_mol, target_mol)]\n        \n    # 合成路径\n    curr_path = [Chem.MolToSmiles(curr_mol)] + child_paths[0]\n    \n    return curr_path\n\n\n# main\ndef multi_step_retrosynthesis_planning(starting_molecules, target_molecules):\n    all_paths = []\n    for start_mol in starting_molecules:\n        for target_mol in target_molecules:\n            path = dfs(start_mol, target_mol)\n            if path is not None:\n                all_paths.append(path)\n\n    return all_paths\n\nfrom rdkit.Chem import Draw\nmol_path_list = multi_step_retrosynthesis_planning(['O-[C;H0;D3;+0:1](-[C:2])=[O;D1;H0:3]'], ['[C:4]-[N;H0;D3;+0:5](-[C:6])-[C;H0;D3;+0:1](-[C:2])=[O;D1;H0:3]'])\nfor mol in mol_path_list:\n    Draw.ShowMol(mol, size=(150,150), kekulize=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install rdkit","metadata":{"execution":{"iopub.status.busy":"2023-06-16T12:43:07.064446Z","iopub.execute_input":"2023-06-16T12:43:07.064826Z","iopub.status.idle":"2023-06-16T12:43:23.485792Z","shell.execute_reply.started":"2023-06-16T12:43:07.064796Z","shell.execute_reply":"2023-06-16T12:43:23.484642Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit) (1.23.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit) (9.5.0)\nInstalling collected packages: rdkit\nSuccessfully installed rdkit-2023.3.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from rdkit import Chem\nfrom rdkit.Chem import AllChem\n\n# Load the models for Tasks 1 and 2\nmodel_task1 = load_model_task1()\nmodel_task2 = load_model_task2()\n\n# Define the target molecule and product molecule for Task 3\ntarget_mol = 'CC(=O)Nc1ccc(C(=O)O)c(c1)C(=O)O'\nproduct_mol = 'CC(=O)Nc1ccc(cc1C(=O)O)C(=O)O'\n\n# Convert the target and product molecules to RDKit molecules\ntarget_mol = Chem.MolFromSmiles(target_mol)\nproduct_mol = Chem.MolFromSmiles(product_mol)\n\n# Generate possible reactants for the target molecule using the model from Task 1\npossible_reactants = generate_possible_reactants(model_task1, target_mol)\n\n# Evaluate the cost of each possible reactant using the model from Task 2\nreactant_costs = []\nfor reactant in possible_reactants:\n    fp = get_fingerprint([reactant])[0]\n    cost = evaluate_cost(model_task2, fp)\n    reactant_costs.append(cost)\n\n# Choose the reactant with the lowest cost as the starting material for synthesis planning (Task 3)\nstarting_reactant = possible_reactants[np.argmin(reactant_costs)]\n\n# Predict the reaction template for the synthesis pathway using the models from Tasks 1 and 3\nreaction_template = predict_reaction_template(model_task1, starting_reactant, product_mol)\n\n# Print the results\nprint('Possible reactants: ', [Chem.MolToSmiles(mol) for mol in possible_reactants])\nprint('Reactant costs: ', reactant_costs)\nprint('Starting material: ', Chem.MolToSmiles(starting_reactant))\nprint('Reaction template: ', reaction_template)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T14:12:56.429299Z","iopub.execute_input":"2023-06-16T14:12:56.429734Z","iopub.status.idle":"2023-06-16T14:12:56.435996Z","shell.execute_reply.started":"2023-06-16T14:12:56.429694Z","shell.execute_reply":"2023-06-16T14:12:56.434903Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Possible reactants:  ['COC(=O)CC(C)(C)Cl', 'CC(C)(C)C(=O)Nc1ccc(C(=O)O)c(c1)C(=O)O', 'COc1ccc(cc1C(=O)O)C(=O)O']\nReactant costs:  [0.9999921915349426, 1.0, 0.9333480596542358]\nStarting material:  COc1ccc(cc1C(=O)O)C(=O)O\nReaction template:  CC(C)(C)C(=O)N>>CO\n\n","output_type":"stream"}]}]}